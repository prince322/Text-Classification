{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets    # Importing dataset module from Sklearn\n",
    "categories=['alt.atheism','comp.graphics','comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware','comp.sys.mac.hardware']\n",
    "traindata=datasets.load_files(r'C:\\Users\\KUNAL\\Downloads\\20news-bydate (1).tar\\20news-bydate (1)\\20news-bydate-train',categories=categories,encoding='ISO-8859-1')   #Training Dataset load by load_files method\n",
    "test_data=datasets.load_files(r'C:\\Users\\KUNAL\\Downloads\\20news-bydate (1).tar\\20news-bydate (1)\\20news-bydate-test',categories=categories,encoding='ISO-8859-1') \n",
    "#Testing Dataset Load by load_files method\n",
    "train=traindata.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function cleans the data by removing all stopwords and punctuation from document\n",
    "def clean_data(a):\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import string\n",
    "    stop_words = set(stopwords.words('english'))      #In stop_words variable storing all unique stopwords\n",
    "    d=\"\"\n",
    "    final_sentence=[]\n",
    "    for w in range(len(a)):\n",
    "        c=word_tokenize(a[w])         #this will make a seprate string of each element in a document at given index\n",
    "        for j in c:\n",
    "            if j.lower() not in stop_words and j not in string.punctuation:\n",
    "                d=d+\" \"+j\n",
    "        final_sentence.append(d.lower())        #After removing stopword it will add the reamining text of that document to the list\n",
    "        d=\"\"\n",
    "    return final_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a dictionary which stores total length of data, each class, no. of rows belong to that particular class, total count of words that belong to particular class and their corresponding word count. It develops for training the model.\n",
    "def fit_function(x_train,count,y_train):\n",
    "    result={}\n",
    "    classes=set(y_train)     #classes variable store unique value of y\n",
    "    result['total_val']=len(y_train)    # stores total length of testing data into a dictionary key i.e 'total_val'\n",
    "    for current_class in classes:\n",
    "        result[current_class]={}\n",
    "        current_row=(y_train==current_class)     #choose only that rows of y_train data which is equal to current class\n",
    "        current_x=x_train[current_row]           #choose only that x_train data which belongs to a particular class \n",
    "        current_y=y_train[current_row]\n",
    "        result[current_class]['total_len_count']=len(current_y)     #Store total length of current_class into 'total_len_count' key of dictionary\n",
    "        result[current_class]['total_sum_count']=current_x.sum()    #Store total count of all words that belong to a particular class into 'total_sum_count' key of dictionary \n",
    "        sum_wrds=current_x.sum(axis=0)\n",
    "        for word,idx in count.vocabulary_.items():\n",
    "            result[current_class][idx]=sum_wrds[0,idx]         #Store count of each word \n",
    "    return result\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function calcluate probabaility of current_class from total testing data and calculate probability of each word to total no. of words\n",
    "def probability(current_class,dictionary,x):\n",
    "    output=np.log(dictionary[current_class]['total_len_count'])-np.log(dictionary['total_val'])      #Calculating probability of current classs to total testing testing data\n",
    "    test=x.tocoo()           #convert scipy_matrix to list which store column no. and row no. and row count of particular row to txt variable\n",
    "    for each in dictionary[current_class].keys():      #Iterate all word from dictionary except 'total_len_count' and 'total_sum_count' which store total length and total sum of counts of words of that particular class\n",
    "        if each=='total_len_count' or each=='total_sum_count':\n",
    "            continue\n",
    "        if each in test.col:       #check wheather that word exist in testing document or not \n",
    "            count_current_class_rows=dictionary[current_class][each] +1     #Calculating count of a word with laplace correction\n",
    "            count_current_class=dictionary[current_class]['total_sum_count']+len(test.col)         #Calculating count of whole word that belong to a particular class with laplace correction                \n",
    "            current_xj_probability=np.log(count_current_class_rows)-np.log(count_current_class)    #calculate probability\n",
    "            output=output+current_xj_probability\n",
    "    return output\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function call probability function for each class and check probability of each class which class has higher probability. After getting high probability that class becomes output\n",
    "def prediction(dictionary,x):\n",
    "    best_class=-1\n",
    "    best_prob=-1000\n",
    "    first=True\n",
    "    for current_class in dictionary.keys():     #Pick all classes from dictionary \n",
    "        if current_class=='total_val':          \n",
    "            continue\n",
    "        prb=probability(current_class,dictionary,x)     #Calling Probability function which returns probability of particular class\n",
    "        if prb>best_prob or first:       #Comparing probability\n",
    "            best_prob=prb\n",
    "            best_class=current_class\n",
    "        first=False\n",
    "    return best_class\n",
    "            \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes dictionary as a parameter which creates during fit function and x_test.It call prediction function for each document .   \n",
    "def predct(dictionary,x_test):\n",
    "    pred=[]\n",
    "    x_data=x_test\n",
    "    for x in x_test:\n",
    "        y=prediction(dictionary,x)   #Call Prediction function for each document of testing data   \n",
    "        pred.append(y)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[304   5   4   0   0]\n",
      " [ 10 354 192  42  31]\n",
      " [  0   0   1   1   1]\n",
      " [  2  13 162 310  56]\n",
      " [  3  17  35  39 297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       313\n",
      "           1       0.91      0.56      0.70       629\n",
      "           2       0.00      0.33      0.01         3\n",
      "           3       0.79      0.57      0.66       543\n",
      "           4       0.77      0.76      0.77       391\n",
      "\n",
      "    accuracy                           0.67      1879\n",
      "   macro avg       0.69      0.64      0.62      1879\n",
      "weighted avg       0.85      0.67      0.74      1879\n",
      "\n",
      "[[307   5   8   1   2]\n",
      " [  7 347 178  30  17]\n",
      " [  0   0   1   0   1]\n",
      " [  1  10 140 300  26]\n",
      " [  4  27  67  61 339]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       323\n",
      "           1       0.89      0.60      0.72       579\n",
      "           2       0.00      0.50      0.01         2\n",
      "           3       0.77      0.63      0.69       477\n",
      "           4       0.88      0.68      0.77       498\n",
      "\n",
      "    accuracy                           0.69      1879\n",
      "   macro avg       0.70      0.67      0.63      1879\n",
      "weighted avg       0.87      0.69      0.76      1879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer     #Importing CountVectorizer creates a matrix in which each unique word is represented by a column of the matrix, and each text sample from the document is a row in the matrix.\n",
    "from sklearn.naive_bayes import MultinomialNB                   #Importing MultinomialNB for text classification\n",
    "from sklearn.metrics import confusion_matrix, classification_report      \n",
    "vect=CountVectorizer(max_features=4000)\n",
    "main_data=clean_data(train)               #Calling Clean_data function for removing stopwords and punctuation from document.\n",
    "\n",
    "\n",
    "x_train=vect.fit_transform(main_data)\n",
    "dictionary=fit_function(x_train,vect,traindata.target)\n",
    "\n",
    "clsfr=MultinomialNB()\n",
    "clsfr.fit(x_train,traindata.target)\n",
    "x_test=vect.transform(test_data.data)\n",
    "y=clsfr.predict(x_test)\n",
    "y_pred=predct(dictionary,x_test)\n",
    "\n",
    "\n",
    "print(confusion_matrix(y,test_data.target))\n",
    "print(classification_report(y,test_data.target))\n",
    "print(confusion_matrix(y_pred,test_data.target))\n",
    "print(classification_report(y_pred,test_data.target))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
